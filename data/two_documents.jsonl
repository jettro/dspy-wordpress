{"post_id": 39906, "title": "Automate customer interaction using OpenAI Assistants.", "url": "https://www.luminis.eu/blog/automate-customer-interaction-using-openai-assistants/", "updated_at": "2024-03-04T17:46:12", "body": "Almost everybody knows what ChatGPT is. At workshops I give, about 90% of the people have used ChatGPT. Most of them know about the company, but only some know about Assistants. That is a pity; assistants can give you or your users a better experience. \u00a0After reading this blog, you understand what OpenAI Assistants are, how they work and what they can do for you and your users.\n\nDALL E generated coffee bar inspired by the famous Starbucks\nThe use case we use for the demo is a coffee-ordering application. Using the chat application, you talk to the barista, ask for suggestions, and order a nice cup of coffee or something else if you do not like coffee. The demo shows how to work with the different aspects of OpenAI assistants. It shows how to use functions and retrievers. It also shows how to combine it with the hybrid search of Weaviate to find recommended products and verify if the product you want is available in the shop.\nUnderstanding of OpenAI Assistants\nAn assistant is there to help your users interact with a set of tools using natural language. An assistant is configured with instructions and can access an LLM and a set of tools. The provider, OpenAI, provides some of these tools. Other tools are functions that you provide yourself. This might sound abstract. Let\u2019s have a look at an example. One of the provided tools is a code interpreter. The assistant uses this tool to execute generated Python code. Using this tool overcomes one of the well-known problems with doing calculations.\n\nInstructions: You are a personal math tutor. Write and run code to answer math questions.\ntools: code_interpreter\nmodel: gpt-4-turbo-preview\n\nThat is enough to initialise an assistant. You provide access to the assistant using a Thread. Think of a Thread as the chat window. You and the assistant both add messages to the Thread. After adding a message to the Thread, you push the run button to start the interaction with the assistant.\nThe following section introduces the assistant we are creating during this blog post.\nThe coffee-ordering assistant\nI like, or better need, a nice cup of coffee every day, multiple times. I am a black coffee fan. But these hip coffee bars have so many choices. For some people, it is hard to choose the proper coffee. Therefore, we create a coffee assistant that can help you make a choice and assist you during the ordering process.\n\nHave yourself a nice cup of coffee.\nFirst, we give the assistant our instructions.\nYou are a barista in a coffee shop. You help users choose the products the shop has to offer. You have tools available to help you with this task. There are tools to find available products, add products, give suggestions based on ingredients, and finalise the order. You are also allowed to do small talk with the visitors.\nWe provide the assistant with the following tools:\n\nfind_available_products\u200a\u2014\u200aFinds available products based on the given input. The result is an array with valid product names or an empty array if no products are found.\nstart_order\u200a\u2014\u200aStart an order, and the result is ERROR or OK. You can use this to notify the user.\nadd_product_to_order\u200a\u2014\u200aAdd a product to the order. The result is ERROR or OK. You can use this to inform the user\nremove_product_from_order\u200a\u2014\u200aRemove a product from the order. The result is ERROR or OK. You can use this to notify the user\ncheckout_order\u200a\u2014\u200acheck out the order. The result is ERROR or OK. You can use this to notify the user\nsuggest_product\u200a\u2014\u200aSuggests a product based on the input. The result is the name of the product that best matches the input.\n\nThe description of the tool or function is essential. The assistant uses the description to determine what tool to use and when.\nThe video below gives you an impression of what we will build.\n\nThe code\nThe first component for an OpenAI assistant is the Assistant class. I am not rewriting the complete OpenAI documentation here. I do point out the essential parts. The assistant is the component that interacts with the LLM, and it knows the available tools.\nThe assistant can be loaded from OpenAI. No get or load function accepts a name. Therefore, we have a method that loops over the available assistants until it finds the one with the provided name. When creating or loading an assistant, you have to provide the tools_module_name. This is used to locate the tools that the assistant can use. It is essential to keep the tools definitions at the exact location so we can automatically call them. More on this feature when talking about runs.\nWe create the coffee assistant using the code below:\n\r\ndef create_assistant():\r\n  name = \"Coffee Assistant\"\r\n  instructions = (\"You are a barista in a coffee shop. You\"\r\n                  \"help users choose the products the shop\"\r\n                  \"has to offer. You have tools available\"\r\n                  \"to help you with this task. You can\"\r\n                  \"answer questions of visitors, you should\"\r\n                  \"answer with short answers. You can ask\"\r\n                  \"questions to the visitor if you need more\"\r\n                  \"information. more ...\")\r\n\r\n  return Assistant.create_assistant(\r\n      client=client,\r\n      name=name,\r\n      instructions=instructions,\r\n      tools_module_name=\"openai_assistant.coffee.tools\")\r\n\nNotice that we created our own Assistant class, not to confuse it with the OpenAI Assistant class. It is a wrapper for the interactions with the OpenAI assistant class. Below is the method to store function tools in the assistant.\n\r\ndef add_tools_to_assistant(assistant: Assistant):\r\n    assistant.register_functions(\r\n        [\r\n            def_find_available_products, \r\n            def_start_order, \r\n            def_add_product_to_order, \r\n            def_checkout_order,\r\n            def_remove_product_from_order, \r\n            def_suggest_coffee_based_on_description\r\n        ])\r\n\nWe have to create the assistant only once, the next time we can load the assistant to use it for interactions. The next code block shows how to load the assistant.\n\r\ntry:\r\n    assistant = Assistant.load_assistant_by_name(\r\n        client=client, \r\n        name=\"Coffee Assistant\",\r\n        tools_module_name=\"openai_assistant.coffee.tools\")\r\n    logging.info(f\"Tools: {assistant.available_tools}\")\r\nexcept AssistantNotFoundError as exp:\r\n    logging.error(f\"Assistant not found: {exp}\")\r\n    raise exp\r\n\nLook at the complete code for the Assistant class at this location.\nThreads\nThe thread is an interaction between a user and the assistant. Therefore, a Thread object is unique per user. In the application, we use the streamlid session to store the thread_id. Therefore, each new session means a new Thread. The thread is responsible for accepting messages and sending them to the assistant. After a message is sent, a response message is awaited. Each interaction with an assistant is done using a run. The image below presents the flow of the application using these different components.\nOverview of the Assistant flow: First, the user creates a Thread. Next, the user sends a message to the Thread and runs the Thread against the Assistant. The Assistant knows all the available tools and asks the LLM what to do. If a tool needs to be called, the Assistant outputs that request. Our Assistant knows how to call the Tools, but this is the client application. The tool\u2019s output is returned to the LLM, and an answer is generated.\nIt is essential to understand that our Assistant wraps the OpenAI Assistant. Calling the tools is done using our Assistant. Detecting the difference between an output with an answer and an output with the request to call a tool is done using the status of the run. If the status is requires_action, our Assistant finds the tool_calls and calls the tools. This is what happens in the following code block taken from the thread.py.\n\r\ndef __handle_run(self, run: Run) -> Run:\r\n    run = self.__verify_run(run_id=run.id)\r\n\r\n    while run.status == \"requires_action\":\r\n        logger_thread.debug(f\"Run {run.id} requires action\")\r\n        tools_calls = run.required_action.submit_tool_outputs.tool_calls\r\n\r\n        tool_outputs = []\r\n        for tool_call in tools_calls:\r\n            result = self.assistant.call_tool(\r\n                tool_call.function.name, \r\n                json.loads(tool_call.function.arguments))\r\n            logger_thread.debug(f\"Result of call: {result}\")\r\n            tool_outputs.append({\r\n                \"tool_call_id\": tool_call.id,\r\n                \"output\": result\r\n            })\r\n        run = self.client.beta.threads.runs.submit_tool_outputs(\r\n            run_id=run.id,\r\n            thread_id=self.thread_id,\r\n            tool_outputs=tool_outputs\r\n        )\r\n        run = self.__verify_run(run_id=run.id)\r\n\r\n    logger_thread.info(f\"Handle run {run.id} completed.\")\r\n    return run\r\n\r\ndef __verify_run(self, run_id: str):\r\n    \"\"\"\r\n    Verify the status of the run, if it is still in \r\n    progress, wait for a second and try again.\r\n    :param run_id: identifier of the run\r\n    :return: the run\r\n    \"\"\"\r\n    run = self.client.beta.threads.runs.retrieve(\r\n        run_id=run_id, thread_id=self.thread_id)\r\n    logger_thread.debug(f\"Run: {run.id}, status: {run.status}\")\r\n    if run.status not in [\"in_progress\", \"queued\"]:\r\n        return run\r\n    time.sleep(1)\r\n    return self.__verify_run(run_id=run.id)\nNotice how we use the __verify_run function to check the status of the run. If the run is queued or in_progress, we wait for it to finish.\nThe source code for the thread can be found at this location.\nTools\nWe already mentioned the tools that the assistant can use. We have to provide the description of the tool to the Assistant. The following code block shows the specification for one function.\n\r\ndef_suggest_coffee_based_on_description = {\r\n    \"name\": \"suggest_coffee_based_on_description\",\r\n    \"description\": (\"Suggests a product based on the given \"\r\n                    \"ingredients. The result is a valid product \"\r\n                    \"name or an empty string if no products \r\n                    \"are found.\"),\r\n    \"parameters\": {\r\n        \"type\": \"object\",\r\n        \"properties\": {\r\n            \"input\": {\r\n                \"type\": \"string\",\r\n                \"description\": \"The coffee to suggest a coffee for\"\r\n            }\r\n        },\r\n        \"required\": [\"input\"]\r\n    }\r\n}\r\n\nIn the code block you see the name, this is important to us. We use the name to call the function. Therefore the name of the function needs to be the same as specified here. The description is really important to the LLM to understand what the tools brings. The parameters are the values provided by the LLM to call the tool with. Again, the description is really important for the LLM to understand what values to provide.\nIn this example we use Weaviate to recommend a drink using the provided text. The next code block shows the implementation.\n\r\ndef suggest_coffee_based_on_description(input: str):\r\n    weaviate = AccessWeaviate(\r\n        url=os.getenv(\"WEAVIATE_URL\"),\r\n        access_key=os.getenv(\"WEAVIATE_ACCESS_KEY\"),\r\n        openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\r\n\r\n    result = weaviate.query_collection(\r\n        question=input, collection_name=\"coffee\")\r\n\r\n    weaviate.close()\r\n\r\n    if len(result.objects) == 0:\r\n        logger_coffee.warning(\"No products found\")\r\n        return \"\"\r\n\r\n    return result.objects[0].properties[\"name\"]\r\n\nConcluding\nThis blog post intends to give you an idea of what it means to work with Assistants. Check the code repository if you want to try it out yourself. The readme file contains the order in which you have to run the different scripts. One is to create the Assistant, one is to load the data into Weaviate, and one is to run the sample application.\nHope you like the post, feel free to comment or get in touch if you have questions.\nReferences\n\nhttps://platform.openai.com/docs/assistants/overview\nhttps://github.com/jettro/ai-assistant\n\n", "tags": ["Assistant", "Generative AI", "OpenAI"], "categories": ["Blog", "Machine learning &amp; AI"]}
{"post_id": 39930, "title": "Nieuwe lichting IT-toptalenten van Thales, de Belastingdienst en Luminis rondt succesvol Accelerate traject af", "url": "https://www.luminis.eu/blog/nieuwe-lichting-it-toptalenten-van-thales-de-belastingdienst-en-luminis-rondt-succesvol-accelerate-traject-af/", "updated_at": "2024-03-05T14:59:30", "body": "Traditiegetrouw wordt het Accelerate traject afgerond in de hangar op vliegveld Teuge. Tijdens het feestelijke graduation event krijgt een nieuwe lichting deelnemers hun welverdiende Accelerate wings opgespeld.\n\nIn dit nieuwe, versnelde Accelerate traject van tien maanden hebben de Belastingdienst, Thales en Luminis voor de derde keer de handen ineengeslagen. Accelerate is een op maat gemaakt opleidingstraject voor software toptalenten van de drie organisaties. In deze nieuwste versie, Accelerate Craftsmanship, krijgen minder ervaren talenten de kans om een sprong in hun ontwikkeling te maken. Talenten die nog niet direct toe zijn aan een leiderschapspositie maar wel grote stappen in die richting kunnen zetten.\nDe twintig deelnemers en elf coaches ronden dit traject met succes af, en vieren dit op het feestelijke graduation event te midden van collega\u2019s, vrienden en familie.\nTijdens het graduation event krijgen de deelnemers de kans om een afsluitende speech te geven over hun ervaringen tijdens het opleidingstraject. Zo vertelt deelnemer Lennaerd Bakker van de Belastingdienst:\n\u201cIk heb geleerd op zoek te gaan naar datgene wat mij motiveert en waar ik enthousiast van word. Daardoor heb ik een nieuwe passie gevonden, doelen gesteld, doelen behaald, en ben ik positiever. Ik wil iedereen meegeven: Ga op zoek naar hetgeen waar jij blij van wordt, houd dat vast, en laat het niet meer los.\u201d\nNaast soms ontroerende speeches van de deelnemers, krijgt ook Bert Ertman, VP Technology bij Luminis en initiatiefnemer van Accelerate, de kans om wat afsluitende woorden te delen. Hij roept de deelnemers op om buiten hun comfortzone te blijven treden: \u201cLeer groter denken, verbind er een doel aan vanuit je persoonlijke waarden, sorteer je acties op \u2018lef\u2019 en \u2018just do it!\u2019\u201d.\nAccelerate Craftsmanship is het derde traject in een succesvolle Accelerate-reeks. Vanuit een initiatief van Thales en Luminis startte in 2020 het eerste traject om tech-toptalent uit de eigen organisatie klaar te stomen voor een toekomst als softwareleiders. Het centrale thema in dit derde traject is Software Craftsmanship, belicht vanuit zowel technisch inhoudelijk vlak maar vooral in combinatie met persoonlijke ontwikkeling.\nHet persoonlijke ontwikkeltraject wordt in samenwerking met How Company gerealiseerd. How Company is sinds het eerste traject partner van Accerelate, en ziet door middel van hun communicatie- en persoonlijk leiderschapstrainingen hoe de deelnemers veranderen. Jeroen Ogier, trainer bij How Company en nauw betrokken bij Accelerate vertelt:\n\u201cDoordat de deelnemers persoonlijke doelen stellen en daar leren actief mee aan de gang te gaan, worden gedachten en idee\u00ebn echt omgezet in concrete resultaten. Dit leidt tot bijzondere ervaringen, groei en ontwikkeling. Het is in \u00e9\u00e9n woord fantastisch om hierin namens How Company een partner te zijn!\u201d\nDat Accelerate het beoogde doel, IT-toptalent klaarstomen voor de top van het tech-landschap, waarmaakt, beaamt Robert van den Breemen, Teamleider Concern IT-Architecten bij de Belastingdienst:\n\u201cHet succes van het Accelerate programma onderstreept het belang van vakmanschap in de ontwikkeling van talentvolle collega\u2019s. De Belastingdienst kiest ervoor om te investeren in het talent en dit te faciliteren met dit waardevolle ontwikkeltraject. Accelerate gaat niet alleen in op de technische vaardigheden maar ook op de persoonlijke ontwikkeling en het bevorderen van een cultuur van continue persoonlijke en professionele groei. Door het aanbieden van dit traject krijgen de talenten de mogelijkheid om te excelleren en te groeien.\u201d\n\nDe voorgaande trajecten, waarin ook werd samengewerkt met de Belastingdienst en Thales, vormden de basis van deze verkorte Accelerate versie (10 maanden in plaats van 18 maanden red.) waarin de meest relevante onderwerpen en sessies uit eerdere trajecten aan bod kwamen. Of het succes van de eerste twee traject ge\u00ebvenaard kon worden in dit verkorte programma was in het begin wel even spannend, vertelt Henk van Steeg, Head Software Engineering bij Thales:\n\u201cDe vraag of de succesformule van Accelerate ook in tien maanden werkt kan ik ondertussen volmondig met \u2018ja\u2019 beantwoorden. In deze tien maanden hebben we veel collega\u2019s een enorme groei zien doormaken waarbij ze nu meer impact maken dan ze zelf voor mogelijk hielden. Als groeiend bedrijf helpen dergelijke trajecten ons enorm om samen met deze collega\u2019s de uitdagingen aan te kunnen.\u201d\nOok Luminis heeft het eerste Accelerate Craftsmanship als succesvol ervaren. Met elk afgerond programma wordt de succesformule van Accelerate alleen maar beter, en het Craftsmanship-programma is een welkome aanvulling op het Accelerate Leadership-traject, zegt ook Jeroen Bouvrie, Director of Operations bij Luminis en stuurgroeplid van Accelerate:\n\u201cAccelerate Craftsmanship heeft laten zien dat de basis van het Accelerate programma zeer geschikt is om de ontwikkeling van deelnemers die nog minder ver in hun carri\u00e8re zijn te versnellen. Door de inmiddels beproefde mix van human skills en technische skills zie je dat de deelnemers echt gegroeid zijn als mens. Ook wanneer je nog niet toe bent aan een meer leadership-achtige rol, laat deze variant van Accelerate zien dat je grote stappen kan maken in je ontwikkeling.\u201d\nNa tien maanden kijken we terug op een bijzonder waardevol ontwikkeltraject. De afgelopen maanden hebben de deelnemers hard gewerkt aan hun skillset, overwonnen ze samen talloze uitdagingen en behaalden ze persoonlijke doelstellingen. We kijken uit naar de impact die deze groep Accelerate-deelnemers gaat hebben op onze organisaties, nu in en de toekomst.\nMeer weten over het Accelerate-programma of IT-trainingen? Bekijk de website van de Luminis Academy of neem contact op met Louis Pouwels, contactpersoon van de Luminis Academy (academy@luminis.eu).\n", "tags": [], "categories": ["Blog", "News"]}
{"post_id": 38593, "title": "Hands-On with Observability: Installing Elasticsearch and Kibana", "url": "https://www.luminis.eu/blog/hands-on-with-observability-installing-elasticsearch-and-kibana/", "updated_at": "2023-08-18T10:23:56", "body": "Following our previous discussion on the fundamentals of Elastic Stack and observability while using Elastic Stack, we\u2019re set to take our exploration to the next level. In this chapter, we shift our focus from theory to practice, diving deep into the setup and utilization of Elasticsearch and Kibana via Docker.\nBefore we begin, ensure you have Docker installed and running on your machine. If not, you can download it here.\nDiving into Observability: The Docker-Facilitated Elasticsearch and Kibana Setup\nAs we embark on this journey to enhance application observability with Elasticsearch, our first task involves creating an Elasticsearch cluster tailored to store and process our specific data. This is generally achieved through a series of steps, including the installation of Elasticsearch, the configuration of indices and mappings, as well as the establishment of data ingestion pipelines to collect and manipulate data from a variety of sources. Today, however, our focus is centered on the initial setup \u2014 the installation of Elasticsearch and Kibana facilitated by Docker.\nDeploying Elasticsearch Using Docker CLI\nYour journey into application observability with Elasticsearch starts with setting up an Elasticsearch cluster. To do this, pull the Docker image with the following command:\ndocker pull docker.elastic.co/elasticsearch/elasticsearch:8.7.0\nNow that you have the image, you can run the following commands to start a single-node Elasticsearch cluster for development:\n# create a new docket network for Elasticsearch and Kibana\r\ndocker network create elastic\r\n\r\n# start Elasticsearch in Docker. Generates credentials --> Save it somewhere!\r\ndocker run --name es01 --net elastic -p 9200:9200 -it docker.elastic.co/elasticsearch/elasticsearch:8.7.0\r\n\r\n# copy the security certificate from Docker to local\r\ndocker cp es01:/usr/share/elasticsearch/config/certs/http_ca.crt .\r\n\r\n# open a new terminal and verify that you can connect to your cluster\r\ncurl --cacert http_ca.crt -u elastic https://localhost:9200\nMake sure you copy the generated password and enrollment token and save them in a secure location. These values are shown only when you start Elasticsearch for the first time. You\u2019ll use these to enroll Kibana with your Elasticsearch cluster and log in.\nOnce the Elasticsearch cluster is set up and configured, developers can use tools like Kibana to create dashboards and charts to visualize the data and identify trends and issues. Kibana is a source-available data visualization dashboard software for Elasticsearch.\nDeploying Kibana Using Docker CLI\nWith the Elasticsearch cluster now set up, we\u2019ll turn our attention to Kibana, a powerful tool for visualizing Elasticsearch data:\n# start Kibana in Docker and connect it to existing Elasticsearch cluster\r\ndocker run --name kib-01 --net elastic -p 5601:5601 docker.elastic.co/kibana/kibana:8.7.0\nThis will start Kibana in docker and will output the next to the terminal when done:\n\nKibana has not been configured.\nGo to\u00a0http://0.0.0.0:5601/?code=579012\u00a0to get started.\n\nWhen you click on the link you will see this screen:\n\nEnter your enrollment token and generated password from before and you will get access to Kibana.\n\nRolling Up Our Sleeves: Diving Into Practical Application\nAs we pivot from theory to practice, our narrative unfolds around two main applications: an E-commerce Website (Application A) and an Inventory Management Service (Application B).\n\nE-commerce Website (Application A): it could include features like user registration, product browsing, adding to cart, and purchase transactions.\nInventory Management Service (Application B): This could be a back-end microservice that manages the inventory for the e-commerce website. It could have features like adding new stock, updating existing stock, marking stock as expired, etc.\n\n\n\u00a0\nIntroducing Dev Tools: Our Gateway to Observability in Elasticsearch\nEager to start communicating directly with Elasticsearch? You\u2019re in luck! By navigating to the Management \u2192 Dev Tools in Kibana, you\u2019ll gain direct access. This powerful tool enables us to execute HTTP requests against the Elasticsearch REST API, facilitating operations like creating indices, adding documents, and running queries. We\u2019ll now create two indices to accommodate our different logs: \u2018ecommerce_app_logs\u2019 for the E-commerce application and \u2018inventory_management_logs\u2019 for the Inventory Management service.\nDeploying Indices: Laying the Groundwork\nInitiate your journey with index creation using the following commands in Dev Tools:\nPUT /ecommerce_app_logs\r\n{\r\n  \"mappings\": {\r\n    \"properties\": {\r\n      \"application-name\": {\r\n        \"type\": \"text\"\r\n      },\r\n      \"timestamp\": {\r\n        \"type\": \"date\"\r\n      },\r\n      \"log_level\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"message\": {\r\n        \"type\": \"text\"\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nPUT /inventory_management_logs\r\n{\r\n  \"mappings\": {\r\n    \"properties\": {\r\n      \"application-name\": {\r\n        \"type\": \"text\"\r\n      },\r\n      \"timestamp\": {\r\n        \"type\": \"date\"\r\n      },\r\n      \"log_level\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"message\": {\r\n        \"type\": \"text\"\r\n      }\r\n    }\r\n  }\r\n}\nThese commands generate the necessary environment for data ingestion, defining the properties of each document that will be inserted into these indices.\nHowever, in production environments, it\u2019s often more scalable and maintainable to utilize index templates. Index templates provide a way to automatically set up mappings, settings, and aliases as new indices are created. By adopting index templates, you can ensure that every new index conforms to a pre-defined structure, making your data ingestion process more streamlined and consistent. This not only reduces the risk of manual configuration errors but also simplifies operations when dealing with a multitude of similar indices. If you\u2019re eager to learn about index templates, you can explore this subject further in this blog from Luminis colleague Jettro Coenradie. Don\u2019t worry if you prefer to stay tuned here, as index templates will also be covered later in this series.\nFeeding Data: Populating Our Indices\nNow that we made these indices we can start adding documents/logs to them.\nPOST /ecommerce_app_logs/_doc\r\n{\r\n  \"application-name\": \"ecommerce_app\",\r\n  \"timestamp\": \"2023-07-24T14:00:23\",\r\n  \"log_level\": \"INFO\",\r\n  \"message\": \"User 'john_doe' successfully logged in\"\r\n}\r\n\r\nPOST /inventory_management_logs/_doc\r\n{\r\n  \"application-name\": \"inventory_management\",\r\n  \"timestamp\": \"2023-07-24T10:15:00\",\r\n  \"log_level\": \"INFO\",\r\n  \"message\": \"New shipment of 'Samsung Galaxy S20' arrived. Quantity: 100\"\r\n}\nAs we progress, we\u2019ll explore automated ways of populating these indices, particularly through tools such as Filebeat and Logstash.\nPeeking at Our Data: Exploring the Discover Tab\nCongratulations on taking your first steps toward indexing and data ingestion. To view your logs, head over to the Analytics \u2192 Discover tab in Kibana. All your logs appear here, but should you need to focus on a specific application, simply add a filter. This not only organizes your data but also sets the stage for more advanced data manipulation techniques we\u2019ll delve into in the future.\n\n\nAssessing Our Initial Journey Into Observability\nHow did your journey into observability start? Was your path clear and straightforward, or did you grapple with unexpected obstacles? Either way, remember that every hurdle overcome is a stepping stone toward mastery. We\u2019d love to hear your stories, your triumphs, and even your challenges. So, feel free to share your experiences in the comments below!\nAnd don\u2019t forget: our exploration into the world of Elasticsearch-driven observability is just beginning. In our next post, we\u2019ll expand our knowledge, shifting from the ingestion of data to its management. We\u2019ll delve deeper into managing the index life-cycle and ensuring our data remains organized and accessible, even as it grows. So, stay tuned for more hands-on guidance in our observability series. Together, let\u2019s unlock the power of data and transform how we see our applications.\n", "tags": [], "categories": ["Blog", "Search"]}
